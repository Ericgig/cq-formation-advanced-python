{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Using Multiple Cores\n",
    "---\n",
    "\n",
    "The reference Python implementation, CPython, only support the execution of one thread at a time. On modern hardware, we can leverage the power of two, four or even more cores, on one machine, using the multiprocessing module. Be aware that there is also a threading module, which lets you use a shared-memory model, but won't let you take full advantage of the underlying hardware. See [GIL description](https://wiki.python.org/moin/GlobalInterpreterLock) for more information.\n",
    "\n",
    "When using the multiprocessing module, we use a distributed memory model. That is, a variable, in two different processes, will each have their own values. Communication and synchronization must then be explicit. As with anything Python, the multiprocessing module makes this simple.\n",
    "\n",
    "We'll start back with the first (non-optimized) example for PI approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def approx_pi(intervals):\n",
    "    pi = 0.0\n",
    "    for i in range(intervals):\n",
    "        pi += (4 - 8 * (i % 2)) / (float)(2 * i + 1)\n",
    "    return pi\n",
    "\n",
    "def approx_pi_main(intervals)\n",
    "    t1 = time.clock()\n",
    "    pi = approx_pi(intervals)\n",
    "    t2 = time.clock()\n",
    "    print(\"PI is approximately %.16f, Error is %.16f\"%(pi, abs(pi - math.pi)))\n",
    "    print(\"Time = %.16f sec\\n\"%(t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this into context, let's measure the run time again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approx_pi_main(100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When parallelizing, the first thing to decide is how to distribute our data. We want to try and balance the workload fairly amongst all processes. In this case, this is easy as each process will need to loop (about) the same number of time.\n",
    "\n",
    "Having a look back at our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approx_pi(intervals):\n",
    "    pi = 0.0\n",
    "    for i in range(intervals):\n",
    "        pi += (4 - 8 * (i % 2)) / (float)(2 * i + 1)\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take as an input a number of intervals to compute and loop from 0 to intervals-1. One approach could be to accept two parameters: start (inclusive) and end (exclusive). Now our function would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approx_pi(start, end):\n",
    "    pi = 0.0\n",
    "    for i in range(start, end):\n",
    "        pi += (4 - 8 * (i % 2)) / (float)(2 * i + 1)\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single call will need to be replaced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = approx_pi(intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we can prepare those intervals. We'll assume 4 processes for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    n = int(sys.argv[1])\n",
    "    chunk_size = n/4\n",
    "    intervals = map(lambda p: [p*chunk_size, p*chunk_size+chunk_size], range(4))\n",
    "    intervals[-1][1] = max(intervals[-1][1], n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line is to make sure that if the number of iterations is not entirely divisible by the number of processes, we do them in the last process instead. If we output those intervals, for 4 processes and 100 million iterations, we get the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    print \"Intervals: \",intervals\n",
    "    \n",
    "~~~ {.output}\n",
    "Intervals:  [[0, 25000000], [25000000, 50000000], [50000000, 75000000], [75000000, 100000000]]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our input data split up correctly, we can try to apply our new function, without any parallelization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pi = sum(map(approx_pi, intervals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will apply the approx_pi on each interval, summing the partial sums at the end. This kind of operation is called a reduction and is a fundamental concept in parallel computing. Running it again should yield the right result, in about the same run time as before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approx_pi_main(100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last missing piece is the actual parallel processing, for which we'll use the Pool.map parallel implementation of the map algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from multiprocessing import Pool\n",
    "...\n",
    "    p = Pool(4)\n",
    "    pi = sum(p.map(approx_pi, intervals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's run it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approx_pi_main(100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the answer is right, the error margin is also good, but that the timing code is way off. It took about 10 seconds to run but we display only 0.03 sec. This is because we use the time.clock function, which is dependent on the current process (start at 0 when the process is launched) and it is confused when starting other processes. Although a little less precise, we'll change the time.clock function calls to time.time, which doesn't have this limitation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    t1 = time.time()\n",
    "    \n",
    "    n = int(sys.argv[1])\n",
    "    chunk_size = n/4\n",
    "    intervals = map(lambda p: [p*chunk_size, p*chunk_size+chunk_size], range(4))\n",
    "    intervals[-1][1] = max(intervals[-1][1], n)\n",
    "\n",
    "    p = Pool(4)\n",
    "    pi = sum(p.map(approx_pi, intervals))\n",
    "\n",
    "    t2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which yields the following run time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approx_pi_main(100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is pretty close to a 4 times speedup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Baby Genomics {.challenge}\n",
    "> \n",
    "> Use a pool of 4 workers and its map function to parallelize the baby-genomic.py code.\n",
    ">\n",
    "> __Tip__: use the edProxy() function in order to call the real editDistance function.\n",
    ">\n",
    "> __Bonus__: use the [asynchronous map function](https://docs.python.org/2/library/multiprocessing.html#multiprocessing.pool.multiprocessing.Pool.map_async) and use the printRes function as a callback to print the results.\n",
    ">\n",
    "> The solution can be found in the solutions/baby-genomic.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load cq-formation-advanced-python/exercices/baby-genomic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-Workshop",
   "language": "python",
   "name": "python-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
